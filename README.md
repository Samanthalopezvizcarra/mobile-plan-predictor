# ğŸ“± Mobile plan predictor
Modelo de clasificaciÃ³n para recomendar el plan Ã³ptimo (Smart o Ultra) basado en el comportamiento mensual de los usuarios.

## ğŸ“˜ DescripciÃ³n del proyecto
Una compaÃ±Ã­a mÃ³vil busca sustituir sus planes antiguos y necesita un modelo que recomiende el plan mÃ¡s adecuado para sus clientes: **Smart** o **Ultra**.  

Para lograrlo, se emplearon datos del comportamiento de usuarios que ya han migrado a los planes nuevos.  
El objetivo principal fue entrenar y evaluar un modelo de clasificaciÃ³n que alcance una **exactitud mÃ­nima de 0.75**.

## ğŸ—‚ Dataset
Cada registro contiene informaciÃ³n mensual del usuario:

- `calls`: NÃºmero de llamadas realizadas  
- `minutes`: DuraciÃ³n total de llamadas en minutos  
- `messages`: Mensajes enviados  
- `mb_used`: TrÃ¡fico de internet consumido (MB)  
- `is_ultra`: Plan usado (1 = Ultra, 0 = Smart)

Fuente: `/datasets/users_behavior.csv`

---

## ğŸ› ï¸ Proceso del proyecto
1. **Carga y exploraciÃ³n del dataset.**  
2. **DivisiÃ³n en conjuntos de entrenamiento, validaciÃ³n y prueba.**  
   - Se empleÃ³ una proporciÃ³n clÃ¡sica para clasificaciÃ³n:  
     - Train: 60%  
     - ValidaciÃ³n: 20%  
     - Test: 20%  
3. **Entrenamiento de distintos modelos** variando hiperparÃ¡metros.  
4. **EvaluaciÃ³n en el conjunto de validaciÃ³n** para seleccionar el mejor modelo.  
5. **Prueba final en el conjunto de test.**  
6. **Prueba de cordura (sanity check)** para verificar que el modelo no solo memoriza.

---

## ğŸ¤– Modelos evaluados
Se entrenaron distintos algoritmos probando configuraciones de hiperparÃ¡metros:

### ğŸ”¹ *RegresiÃ³n LogÃ­stica*
- RÃ¡pida y simple  
- **Peor desempeÃ±o en este dataset**

### ğŸ”¹ *Ãrbol de DecisiÃ³n*
- Buen desempeÃ±o  
- Accuracy cercano al mejor modelo  
- Ãštil si se busca **rapidez** y fÃ¡cil interpretabilidad

### ğŸ”¹ *Bosque Aleatorio (Random Forest)* â€“ **Modelo ganador**
- Mejor exactitud general  
- Mejor manejo de variaciones en el comportamiento del usuario  
- HiperparÃ¡metros Ã³ptimos encontrados:
  - `max_depth = 4`
  - `n_estimators = 10`

---

## ğŸ† Resultados
El **Bosque Aleatorio** logrÃ³ la mayor exactitud y cumpliÃ³ con el umbral esperado.  
Los modelos quedaron ordenados asÃ­ (de mayor a menor precisiÃ³n):

1. **RandomForestClassifier** â€” *Mejor accuracy*
2. **DecisionTreeClassifier**
3. **LogisticRegression** â€” *Menor accuracy*

---

## ğŸ§ª Prueba en el conjunto de test
El modelo seleccionado se probÃ³ en datos nunca antes vistos, confirmando su capacidad de generalizaciÃ³n.

---

## ğŸ“ Conclusiones
- El **Bosque Aleatorio** con `max_depth=4` y `n_estimators=10` fue el mejor modelo para este problema.  
- El **Ãrbol de DecisiÃ³n** tambiÃ©n obtuvo resultados altos, Ãºtil si se requiere velocidad o menor complejidad computacional.  
- La **RegresiÃ³n LogÃ­stica** no modelÃ³ bien las relaciones presentes en los datos.  
- El modelo cumple con los requisitos del proyecto y supera el nivel mÃ­nimo de exactitud solicitado.

---

## ğŸ“¦ TecnologÃ­as usadas
- Python  
- pandas  
- scikit-learn  
- numpy  
- matplotlib / seaborn (para exploraciÃ³n)
